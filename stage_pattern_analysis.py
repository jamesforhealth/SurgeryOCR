#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from __future__ import annotations

import argparse
import json
import math
from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import cv2
import numpy as np
from PIL import Image

from extract_frame_cache import iterate_frames, get_frame_cache_dir
from utils.get_configs import load_diff_rules, load_pattern_name_mapping, read_surgery_stage_rois
from utils.get_paths import resolve_video_analysis_dir
from utils.cv_processing import calculate_rmse, calculate_ndarray_diff

# -----------------------------
# Data structures
# -----------------------------

@dataclass
class RegionPattern:
    pattern_id: int
    array: np.ndarray  # reference pattern image (RGB for PEDAL, binary for others)


@dataclass
class Segment:
    pattern_id: int
    start_frame: int
    end_frame: int
    avg_rmse: float


# -----------------------------
# Utilities
# -----------------------------

def debug_pause(args: argparse.Namespace, message: str):
    """å¦‚æœå•Ÿç”¨äº’å‹•æ¨¡å¼ï¼Œå‰‡æš«åœç¨‹å¼"""
    if args.interactive:
        input(f"    â””â”€â”€ â¸ï¸  {message} (æŒ‰ Enter ç¹¼çºŒ)...")

def binarize_otsu(image_rgb: np.ndarray) -> np.ndarray:
    """Return a 2D uint8 binary image (0/255) using OTSU on gray."""
    gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    return binary


def _load_region_patterns(cache_dir: Path, region_name: str) -> List[RegionPattern]:
    region_dir = cache_dir / region_name
    if not region_dir.exists():
        return []
    patterns: List[RegionPattern] = []
    for npy_path in sorted(region_dir.glob("*.npy")):
        try:
            arr = np.load(npy_path)
            if not isinstance(arr, np.ndarray):
                continue
            arr = arr.astype(np.float32, copy=False)
            try:
                pid = int(npy_path.stem)
            except ValueError:
                continue
            patterns.append(RegionPattern(pattern_id=pid, array=arr))
        except Exception:
            continue
    return patterns


def _get_analysis_candidate(roi_input: np.ndarray, region_name: str, region_config: Dict, args: argparse.Namespace, frame_idx: int, input_is_bgr: bool = False) -> np.ndarray:
    """æ ¹æ“šå€åŸŸé…ç½®ï¼Œå¾åŸå§‹ROIä¸­æº–å‚™ç”¨æ–¼åˆ†æçš„åœ–åƒé™£åˆ—"""
    analysis_mode = region_config.get("analysis_mode", "full_roi")
    is_pedal_debug = args.debug_pedal and region_name == "PEDAL"

    if is_pedal_debug:
        print(f"\n[PEDAL DEBUG] Frame {frame_idx} | æ­¥é©Ÿ 2: æº–å‚™åˆ†æåœ–åƒ")
        print(f"    - åˆ†ææ¨¡å¼: {analysis_mode}")

    if region_name == "PEDAL":
        # PEDAL éœ€è¦ RGB æ ¼å¼
        if input_is_bgr:
            roi_rgb = cv2.cvtColor(roi_input, cv2.COLOR_BGR2RGB)
        else:
            roi_rgb = roi_input

        if analysis_mode == "sub_roi":
            sub_coords = region_config.get("sub_roi_coords", [20, 13, 26, 19])
            x1, y1, x2, y2 = sub_coords
            h, w = roi_rgb.shape[:2]
            if x2 > w or y2 > h or x1 < 0 or y1 < 0:
                print(f"    [PEDAL DEBUG] ğŸ”´ è­¦å‘Š: ç²¾ç´°å€åŸŸåº§æ¨™ {sub_coords} è¶…å‡ºROIç¯„åœ {(w, h)}")
                return roi_rgb
            
            cand_array = roi_rgb[y1:y2, x1:x2]
            if is_pedal_debug:
                print(f"    - è£åˆ‡å¾Œçš„å€™é¸åœ–åƒå°ºå¯¸: {cand_array.shape}")
            return cand_array
        else:
            return roi_rgb
    else:
        # å…¶ä»–å€åŸŸä½¿ç”¨ OTSU äºŒå€¼åŒ– (å¾ Gray)
        if input_is_bgr:
            gray = cv2.cvtColor(roi_input, cv2.COLOR_BGR2GRAY)
        else:
            gray = cv2.cvtColor(roi_input, cv2.COLOR_RGB2GRAY)
            
        _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
        return binary


def _match_best_pattern(
    cand_array: np.ndarray,
    patterns: List[RegionPattern],
    rmse_threshold: float,
    args: argparse.Namespace,
    frame_idx: int,
    region_name: str,
    region_config: Dict[str, Any]
) -> Tuple[Optional[int], Optional[float]]:
    """å¾å€™é¸åœ–åƒé™£åˆ—ä¸­åŒ¹é…æœ€ä½³æ¨£æ¿
    æ¯”å°è¦å‰‡ï¼š
    1. éæ­·æ‰€æœ‰å·²çŸ¥çš„æ¨£æ¿ï¼Œè¨ˆç®—å€™é¸åœ–åƒèˆ‡æ¯å€‹æ¨£æ¿ä¹‹é–“çš„ RMSE å€¼ã€‚
    2. åœ¨æ‰€æœ‰è¨ˆç®—å‡ºçš„ RMSE å€¼ä¸­ï¼Œæ‰¾å‡ºæœ€å°çš„é‚£ä¸€å€‹ã€‚
    3. åªæœ‰ç•¶é€™å€‹æœ€å°çš„ RMSE å€¼åŒæ™‚ä¹Ÿå°æ–¼æŒ‡å®šçš„ `rmse_threshold` æ™‚ï¼Œ
       æ‰å°‡å…¶è¦–ç‚ºä¸€å€‹ç¢ºå®šçš„ã€å”¯ä¸€çš„åŒ¹é…ã€‚
    4. å¦å‰‡ï¼Œå³ä½¿æ‰¾åˆ°äº†æœ€æ¥è¿‘çš„æ¨£æ¿ï¼Œä¹Ÿå› ç›¸ä¼¼åº¦ä¸è¶³è€Œè¦–ç‚ºä¸åŒ¹é…ã€‚
    """
    is_pedal_debug = args.debug_pedal and region_name == "PEDAL"
    analysis_mode = region_config.get("analysis_mode", "full_roi")

    if is_pedal_debug:
        print(f"[PEDAL DEBUG] Frame {frame_idx} | æ­¥é©Ÿ 3: åŸ·è¡Œæ¨£æ¿æ¯”å°")
        print(f"    - å€™é¸åœ–åƒå°ºå¯¸: {cand_array.shape}")
        print(f"    - ä½¿ç”¨çš„é–€æª»å€¼: {rmse_threshold}")
        debug_pause(args, "å³å°‡é–‹å§‹é€ä¸€æ¨£æ¿æ¯”å°")

    if not patterns:
        if is_pedal_debug:
            print("    [PEDAL DEBUG] ğŸ”´ éŒ¯èª¤: æ²’æœ‰è¼‰å…¥ä»»ä½•æ¨£æ¿ï¼Œç„¡æ³•æ¯”å°ã€‚")
        return None, None
    
    cand_array = cand_array.astype(np.float32, copy=False)
    best_pid: Optional[int] = None
    best_rmse: float = float("inf")

    # å„ªåŒ–ï¼šå°‡å¾ªç’°ä¸è®Šé‡ç§»å‡ºå¾ªç’°
    use_sub_roi = (region_name == "PEDAL" and analysis_mode == "sub_roi")
    sub_coords = region_config.get("sub_roi_coords") if use_sub_roi else None
    x1, y1, x2, y2 = (0, 0, 0, 0)
    if sub_coords:
         x1, y1, x2, y2 = sub_coords

    for p in patterns:
        full_ref_array = p.array
        ref_for_comparison = full_ref_array

        if use_sub_roi:
            if full_ref_array.shape[1] > x2 and full_ref_array.shape[0] > y2:
                ref_for_comparison = full_ref_array[y1:y2, x1:x2]
            else:
                if is_pedal_debug:
                    print(f"    [PEDAL DEBUG] ğŸ”´ è­¦å‘Š: æ¨£æ¿ ID {p.pattern_id} (å°ºå¯¸ {full_ref_array.shape}) å¤ªå°ï¼Œç„¡æ³•ä½¿ç”¨ sub_roi åº§æ¨™ {sub_coords} é€²è¡Œè£åˆ‡ã€‚")
                continue

        # å„ªåŒ–ï¼šå…§è¯ RMSE è¨ˆç®—ï¼Œæ¸›å°‘å‡½æ•¸èª¿ç”¨é–‹éŠ·
        if ref_for_comparison.shape != cand_array.shape:
            if is_pedal_debug:
                 print(f"    [DEBUG] ğŸ”´ éŒ¯èª¤: å½¢ç‹€ä¸åŒ¹é…! Pattern: {ref_for_comparison.shape}, Cand: {cand_array.shape}")
            rmse = float("inf")
        else:
            rmse = calculate_rmse(ref_for_comparison, cand_array)

        if is_pedal_debug:
            print(f"    - æ­£åœ¨æ¯”å°æ¨£æ¿ ID: {p.pattern_id} (æ¯”å°å°ºå¯¸: {ref_for_comparison.shape}) -> è¨ˆç®—å‡ºçš„ RMSE: {rmse:.4f}")
        
        if rmse < best_rmse:
            best_rmse = rmse
            best_pid = p.pattern_id
            # å„ªåŒ–ï¼šå¦‚æœå·²ç¶“å®Œå…¨åŒ¹é…ï¼Œå°±ä¸éœ€è¦å†æ‰¾äº†
            if best_rmse == 0.0:
                break

    is_match = best_pid is not None and best_rmse < rmse_threshold
    
    if is_pedal_debug:
        print(f"    - æ¯”å°å®Œæˆã€‚æœ€ä½³åŒ¹é…æ¨£æ¿: {best_pid}, æœ€å° RMSE: {best_rmse:.4f}")
        print(f"    - åˆ¤æ–·çµæœ: {best_rmse:.4f} < {rmse_threshold} ?  -> {'âœ… åŒ¹é…æˆåŠŸ' if is_match else 'âŒ åŒ¹é…å¤±æ•—'}")
        debug_pause(args, "æ¨£æ¿æ¯”å°çµæŸ")

    if is_match:
        return best_pid, best_rmse
    return None, None


def build_segments(
    matches: List[Tuple[int, Optional[int], Optional[float]]],
    pattern_mapping: Dict[str, str]
) -> List[Dict[str, Any]]:
    """
    å¾å¹€åŒ¹é…åˆ—è¡¨ä¸­æ§‹å»ºé€£çºŒçš„ç‰‡æ®µã€‚
    """
    segments: List[Dict[str, Any]] = []
    current_pattern: Optional[int] = None
    start: Optional[int] = None
    rmse_values: List[float] = []

    def close_segment(end_frame: int):
        nonlocal segments, start, current_pattern, rmse_values
        if current_pattern is not None:
            avg_rmse = np.mean(rmse_values) if rmse_values else 0.0
            pattern_name = pattern_mapping.get(str(current_pattern), f"Pattern {current_pattern}")
            segments.append({
                "pattern": current_pattern,
                "pattern_name": pattern_name,
                "start_frame": start,
                "end_frame": end_frame,
                "avg_rmse": float(avg_rmse),
                "frame_count": end_frame - start + 1
            })
            rmse_values = []

    for frame_idx, pattern_id, rmse in matches:
        # None è¦–ç‚ºç©ºç™½å€æ®µï¼Œæœƒä¸­æ–·ä»»ä½•æ­£åœ¨é€²è¡Œçš„ç‰‡æ®µ
        if pattern_id is None:
            close_segment(frame_idx - 1)
            current_pattern = None
            start = None
            rmse_values = []
            continue

        if current_pattern is None:
            current_pattern = pattern_id
            start = frame_idx
            if rmse is not None:
                rmse_values.append(rmse)
            continue

        if pattern_id != current_pattern:
            close_segment(frame_idx - 1)
            current_pattern = pattern_id
            start = frame_idx
            rmse_values = []
            if rmse is not None:
                rmse_values.append(rmse)
        else:
            if rmse is not None:
                rmse_values.append(rmse)

    if current_pattern is not None and start is not None:
        last_frame = matches[-1][0] if matches else 0
        close_segment(last_frame)

    return segments


def analyze_pedal_frame(
    current_roi: np.ndarray,
    prev_roi: Optional[np.ndarray],
    patterns: List[RegionPattern],
    region_config: Dict[str, Any],
    args: argparse.Namespace,
    frame_idx: int
) -> Tuple[Optional[int], Optional[float]]:
    """
    PEDAL å€åŸŸçš„å„ªåŒ–åˆ†æå‡½æ•¸ï¼š
    1. ç¬¬ä¸€å¹€ï¼šç›´æ¥èˆ‡ cache æ¯”å°
    2. å¾ŒçºŒå¹€ï¼šå…ˆèˆ‡å‰ä¸€å¹€æ¯”è¼ƒå·®ç•°ï¼Œè¶…é frame_diff_threshold æ‰é€²è¡Œ cache æ¯”å°
    3. Cache æ¯”å°æ™‚ä½¿ç”¨ cache_hit_threshold åˆ¤æ–·æ˜¯å¦åŒ¹é…
    """
    is_pedal_debug = args.debug_pedal
    sub_coords = region_config.get("sub_roi_coords", [20, 13, 26, 19])
    
    # å¾é…ç½®ä¸­ç²å–å…©å€‹ä¸åŒçš„é–¾å€¼
    frame_diff_threshold = region_config.get("diff_threshold", 30.0)  # å‰å¾Œå¹€å·®ç•°é–€æª»
    cache_hit_threshold = region_config.get("cache_hit_threshold", 40.0)  # cache åŒ¹é…é–€æª»
    
    # è¨˜éŒ„ä¸Šä¸€å¹€çš„åŒ¹é…çµæœï¼ˆç°¡å–®èµ·è¦‹ï¼Œä½¿ç”¨å…¨åŸŸè®Šæ•¸æˆ–é¡å±¬æ€§ï¼Œé€™è£¡ç”¨éœæ…‹è®Šæ•¸æ¨¡æ“¬ï¼‰
    if not hasattr(analyze_pedal_frame, 'prev_match_result'):
        analyze_pedal_frame.prev_match_result = (None, None)
    
    if is_pedal_debug:
        print("="*60)
        print(f"[PEDAL DEBUG] Frame {frame_idx} | PEDAL å€åŸŸåˆ†æé–‹å§‹")
        print(f"    - ç•¶å‰ ROI å°ºå¯¸: {current_roi.shape}")
        print(f"    - å‰å¾Œå¹€å·®ç•°é–€æª»: {frame_diff_threshold}")
        print(f"    - Cache åŒ¹é…é–€æª»: {cache_hit_threshold}")
    
    # ç¬¬ä¸€å¹€ï¼šç›´æ¥èˆ‡ cache æ¯”å°
    if prev_roi is None or frame_idx == 0:
        if is_pedal_debug:
            print(f"    - ç­–ç•¥: ç¬¬ä¸€å¹€ï¼Œç›´æ¥é€²è¡Œ cache æ¯”å°")
        
        cand_array = _get_analysis_candidate(current_roi, "PEDAL", region_config, args, frame_idx)
        pid, rmse = _match_best_pattern(
            cand_array, patterns, cache_hit_threshold, args, frame_idx,
            region_name="PEDAL", region_config=region_config
        )
        analyze_pedal_frame.prev_match_result = (pid, rmse)
        return pid, rmse
    
    # å¾ŒçºŒå¹€ï¼šå…ˆè¨ˆç®—å‰å¾Œå¹€å·®ç•°
    frame_diff = calculate_ndarray_diff(prev_roi, current_roi, sub_coords)
    
    if is_pedal_debug:
        print(f"    - èˆ‡å‰ä¸€å¹€çš„å·®ç•°å€¼: {frame_diff:.2f}")
        print(f"    - å‰å¾Œå¹€å·®ç•°é–€æª»: {frame_diff_threshold}")
        
    if frame_diff <= frame_diff_threshold:
        # å·®ç•°ä¸å¤§ï¼Œæ²¿ç”¨å‰ä¸€å¹€çš„çµæœ
        prev_pid, prev_rmse = analyze_pedal_frame.prev_match_result
        if is_pedal_debug:
            print(f"    - ç­–ç•¥: å·®ç•° â‰¤ {frame_diff_threshold}ï¼Œæ²¿ç”¨å‰ä¸€å¹€çµæœ (Pattern ID: {prev_pid})")
        return prev_pid, prev_rmse
    else:
        # å·®ç•°è¼ƒå¤§ï¼Œé€²è¡Œ cache æ¯”å°
        if is_pedal_debug:
            print(f"    - ç­–ç•¥: å·®ç•° > {frame_diff_threshold}ï¼Œé€²è¡Œ cache æ¯”å°")
            print(f"    - å°‡ä½¿ç”¨ cache åŒ¹é…é–€æª»: {cache_hit_threshold}")
            debug_pause(args, "å³å°‡é–‹å§‹ cache æ¯”å°")
        
        cand_array = _get_analysis_candidate(current_roi, "PEDAL", region_config, args, frame_idx)
        pid, rmse = _match_best_pattern(
            cand_array, patterns, cache_hit_threshold, args, frame_idx,
            region_name="PEDAL", region_config=region_config
        )
        
        # æ›´æ–°è¨˜éŒ„çš„çµæœ
        analyze_pedal_frame.prev_match_result = (pid, rmse)
        
        if is_pedal_debug:
            print(f"    - Cache æ¯”å°çµæœ: Pattern ID {pid}, RMSE: {rmse}")
            if pid is not None:
                print(f"    - âœ… æ‰¾åˆ°åŒ¹é…çš„ Pattern ID {pid} (RMSE {rmse:.2f} < {cache_hit_threshold})")
            else:
                print(f"    - âŒ æ²’æœ‰æ‰¾åˆ°åŒ¹é…çš„ Pattern (æœ€å° RMSE {rmse:.2f} >= {cache_hit_threshold})")
        
        return pid, rmse


# --------------------------------------------------------------------------
# [NEW] StageAnalyzer Class for Pipeline Integration
# --------------------------------------------------------------------------
class StageAnalyzer:
    def __init__(self, roi_config_path: Path, cache_dir: Path, debug: bool = False):
        self.roi_config_path = roi_config_path
        self.cache_dir = cache_dir
        self.debug = debug
        
        # è¼‰å…¥é…ç½®
        self.roi_dict = read_surgery_stage_rois(roi_config_path)
        self.diff_rules = load_diff_rules()
        
        # è¼‰å…¥ Patterns
        self.region_to_patterns: Dict[str, List[RegionPattern]] = {
            region: _load_region_patterns(cache_dir, region) for region in self.roi_dict.keys()
        }
        
        # ç‹€æ…‹è®Šæ•¸
        self.prev_frame_rois: Dict[str, Optional[np.ndarray]] = {r: None for r in self.roi_dict}
        
        # å°ˆé–€ç‚º PEDAL å„ªåŒ–æº–å‚™çš„ç‹€æ…‹
        # æˆ‘å€‘éœ€è¦ç¶­è­· analyze_pedal_frame çš„å…§éƒ¨ç‹€æ…‹ (prev_match_result)
        # ç‚ºäº†é¿å…å¤šå€‹å¯¦ä¾‹äº’ç›¸å¹²æ“¾ï¼Œæˆ‘å€‘å°‡ç‹€æ…‹å­˜åœ¨ instance ä¸­
        self.pedal_prev_match = (None, None) # (pid, rmse)
        
        # [å„ªåŒ–] é å…ˆå‰µå»º mock_args å°è±¡ï¼Œé¿å…æ¯å¹€éƒ½å‰µå»ºæ–°å°è±¡
        self._mock_args = argparse.Namespace(debug_pedal=debug, interactive=False)
        
        # [å„ªåŒ–] é å…ˆè¨ˆç®—æ¯å€‹å€åŸŸçš„é…ç½®å’Œé–¾å€¼
        self._region_configs: Dict[str, Dict] = {}
        self._region_thresholds: Dict[str, float] = {}
        for region_name in self.roi_dict.keys():
            config = self.diff_rules.get(region_name, {})
            self._region_configs[region_name] = config
            self._region_thresholds[region_name] = config.get("diff_threshold", 30.0)
    
    def process_frame(self, frame_bgr: np.ndarray, frame_idx: int, rmse_threshold: Optional[float] = None) -> Dict[str, Dict[str, Any]]:
        """
        è™•ç†å–®ä¸€å¹€ï¼Œå›å‚³è©²å¹€å„å€åŸŸçš„åŒ¹é…çµæœã€‚
        Returns:
            {
                "STAGE": {"pattern_id": 1, "rmse": 12.5},
                "PEDAL": {"pattern_id": None, "rmse": None},
                ...
            }
        """
        results = {}

        for region_name, coords in self.roi_dict.items():
            # [å„ªåŒ–] ä½¿ç”¨é å…ˆç·©å­˜çš„é…ç½®å’Œé–¾å€¼
            region_config = self._region_configs[region_name]
            threshold = rmse_threshold if rmse_threshold is not None else self._region_thresholds[region_name]

            x1, y1, x2, y2 = map(int, coords)
            h, w = frame_bgr.shape[:2]
            
            # é‚Šç•Œæª¢æŸ¥
            if x2 <= x1 or y2 <= y1 or x1 < 0 or y1 < 0 or x2 > w or y2 > h:
                if self.debug:
                    print(f"[è­¦å‘Š] ROI åº§æ¨™ç„¡æ•ˆ {region_name}: {(x1,y1,x2,y2)} è¶…å‡ºç•«é¢ç¯„åœ {(w,h)}ï¼Œè·³é")
                results[region_name] = {"pattern_id": None, "rmse": None}
                continue
                
            roi_bgr = frame_bgr[y1:y2, x1:x2]
            
            pid, rmse = None, None
            
            if region_name == "PEDAL":
                # PEDAL éœ€è¦ RGB é€²è¡Œåˆ†æ
                roi_rgb = cv2.cvtColor(roi_bgr, cv2.COLOR_BGR2RGB)
                
                # æ³¨å…¥ç‹€æ…‹
                analyze_pedal_frame.prev_match_result = self.pedal_prev_match
                
                pid, rmse = analyze_pedal_frame(
                    roi_rgb, self.prev_frame_rois[region_name],
                    self.region_to_patterns.get(region_name, []),
                    region_config, self._mock_args, frame_idx
                )
                
                # ä¿å­˜ç‹€æ…‹
                self.pedal_prev_match = analyze_pedal_frame.prev_match_result
                self.prev_frame_rois[region_name] = roi_rgb.copy() # é€™è£¡é‚„æ˜¯å­˜ RGB ä»¥ä¾›ä¸‹ä¸€å¹€æ¯”è¼ƒ
                
            else:
                # é PEDAL å€åŸŸï¼Œå‚³å…¥ BGR ä¸¦åœ¨ _get_analysis_candidate å…§éƒ¨è½‰ Gray -> Binaryï¼Œçœå» RGB è½‰æ›
                cand_array = _get_analysis_candidate(roi_bgr, region_name, region_config, self._mock_args, frame_idx, input_is_bgr=True)
                patterns = self.region_to_patterns.get(region_name, [])
                if patterns:
                    pid, rmse = _match_best_pattern(
                        cand_array, patterns, threshold, self._mock_args, frame_idx,
                        region_name=region_name, region_config=region_config
                    )
            
            results[region_name] = {"pattern_id": pid, "rmse": rmse}
            
        return results


def analyse_video(
    video_path: Path,
    *,
    roi_config_path: Path,
    cache_dir: Path,
    rmse_threshold: Optional[float] = None,
    output_dir: Optional[Path] = None,
    args: argparse.Namespace,
) -> Path:
    """å°å–®ä¸€å½±ç‰‡é€²è¡Œåˆ†æ"""
    
    # ä½¿ç”¨æ–°çš„ StageAnalyzer Class
    analyzer = StageAnalyzer(roi_config_path, cache_dir, debug=args.debug_pedal)
    
    # ç°¡æ˜“å–å¾—å½±ç‰‡è³‡è¨Š
    cap = cv2.VideoCapture(str(video_path))
    if not cap.isOpened():
        raise SystemExit(f"ç„¡æ³•é–‹å•Ÿå½±ç‰‡: {video_path}")
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT) or 0)
    cap.release()

    region_matches: Dict[str, List[Tuple[int, Optional[int], Optional[float]]]] = {r: [] for r in analyzer.roi_dict}
    
    print(f"ğŸš€ é–‹å§‹ä½¿ç”¨ã€Œå„ªåŒ–çš„ PEDAL å‰å¾Œå¹€æ¯”è¼ƒæ³•ã€åˆ†æå½±ç‰‡: {video_path.name}")
    if args.debug_pedal:
        print("ğŸ•µï¸  å·²å•Ÿç”¨ PEDAL åµéŒ¯æ¨¡å¼ã€‚")

    frames_to_process = total_frames
    if args.debug_pedal:
        frames_to_process = 50
        print(f"âš ï¸  åµéŒ¯æ¨¡å¼ä¸‹ï¼Œåƒ…è™•ç†å‰ {frames_to_process} å¹€ä»¥åŠ é€Ÿé™¤éŒ¯ã€‚")

    # å„ªå…ˆä½¿ç”¨ frame_cacheï¼ˆè‹¥å­˜åœ¨ï¼‰ï¼Œå¦å‰‡å›é€€åˆ°ç›´æ¥è®€å–å½±ç‰‡
    cache_path = get_frame_cache_dir(video_path)
    cache_has_files = cache_path.exists() and any(cache_path.glob("frame_*.jpg"))
    
    if cache_has_files:
        print(f"[è¨Šæ¯] ä½¿ç”¨ frame_cache ä¾†æº: {cache_path}")
        frame_source = iterate_frames(video_path)
    else:
        # å˜—è©¦å¾ extract_frame_cache å°å…¥ generatorï¼Œå¦‚æœå¤±æ•—å‰‡ä½¿ç”¨æœ¬åœ°ç°¡å–®é‚è¼¯
        try:
            from extract_frame_cache import video_frame_generator
            frame_source = video_frame_generator(video_path)
        except ImportError:
            # Fallback: ç°¡å–®çš„ generator
            def simple_gen():
                c = cv2.VideoCapture(str(video_path))
                i = 0
                while True:
                    r, f = c.read()
                    if not r: break
                    if f is not None and f.size > 0:
                        yield i, f
                    i += 1
                c.release()
            frame_source = simple_gen()

    # çµ±ä¸€çš„è™•ç†è¿´åœˆ
    for frame_idx, frame_bgr in frame_source:
        if args.debug_pedal and frame_idx >= frames_to_process:
            break
            
        if frame_idx > 0 and frame_idx % 1000 == 0:
            print(f"  ... æ­£åœ¨è™•ç†å¹€ {frame_idx}/{total_frames}")

        # ä½¿ç”¨ Analyzer è™•ç†
        results = analyzer.process_frame(frame_bgr, frame_idx, rmse_threshold)
        
        # æ”¶é›†çµæœ
        for region_name, res in results.items():
            region_matches[region_name].append((frame_idx, res['pattern_id'], res['rmse']))

    print("âœ… é€å¹€åˆ†æå®Œæˆï¼Œé–‹å§‹å»ºç«‹å€æ®µ...")

    regions_output: Dict[str, List[Dict[str, float]]] = {}
    for region_name, matches in region_matches.items():
        # ä¿éšªï¼šæŒ‰ frame_idx æ’åºï¼Œé¿å…ä»»ä½•ä¾†æºé€ æˆçš„éŒ¯åº
        matches.sort(key=lambda t: t[0])
        # ä½¿ç”¨æ–°çš„ build_segments å‡½æ•¸
        region_pattern_map = load_pattern_name_mapping(Path("config/pattern_name_mapping.json")).get(region_name, {})
        segments = build_segments(matches, region_pattern_map)
        # é¡å¤–é˜²è­·ï¼šä¿®æ­£å¯èƒ½çš„è²  frame_count èˆ‡éŒ¯ä½ end/start
        cleaned_segments: List[Dict[str, Any]] = []
        for seg in segments:
            s = int(seg.get("start_frame", 0))
            e = int(seg.get("end_frame", s))
            if e < s:
                # ä»¥ s ä½œç‚º fallbackï¼Œé¿å…è² å€¼
                e = s
            fc = max(0, e - s + 1)
            seg["start_frame"] = s
            seg["end_frame"] = e
            seg["frame_count"] = fc
            cleaned_segments.append(seg)
        segments = cleaned_segments
        regions_output[region_name] = segments
        non_null = sum(1 for _, pid, _ in matches if pid is not None)
        print(f"[è¨ºæ–·] å€åŸŸ {region_name}: åŒ¹é…å¹€æ•¸ {non_null} / {len(matches)}ï¼Œæ®µè½æ•¸ {len(segments)}")

    video_name = video_path.stem
    if output_dir is None:
        # ä½¿ç”¨çµ±ä¸€çš„è·¯å¾‘è§£æé‚è¼¯ï¼Œæ”¯æŒå­ç›®éŒ„çµæ§‹
        output_dir = resolve_video_analysis_dir(video_path)
    output_dir.mkdir(parents=True, exist_ok=True)
    out_path = output_dir / "stage_analysis.json"

    payload = {
        "video": video_name,
        "total_frames": total_frames,
        "regions": regions_output,
    }

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)

    print(f"âœ… åˆ†æå®Œæˆï¼Œå·²è¼¸å‡º: {out_path}")
    return out_path


def parse_args() -> argparse.Namespace:
    p = argparse.ArgumentParser(description="Compare ROI of each frame against cached patterns and produce stage analysis JSON")
    p.add_argument("--video", "--video-path", dest="video", required=True, type=Path, help="å½±ç‰‡è·¯å¾‘æˆ–è³‡æ–™å¤¾ (.mp4 æª”æˆ–åŒ…å«å¤šæ”¯å½±ç‰‡çš„è³‡æ–™å¤¾)")
    p.add_argument("--roi-config", type=Path, default=Path("config/surgery_stage_rois.json"), help="æ‰‹è¡“éšæ®µROIé…ç½®æª”")
    p.add_argument("--cache-dir", type=Path, default=Path("data/roi_img_caches"), help="å„å€åŸŸå¿«å–åœ–ç‰‡è³‡æ–™å¤¾æ ¹ç›®éŒ„")
    p.add_argument("--threshold", type=float, default=None, help="å…¨åŸŸRMSEé–€æª»å€¼ (è‹¥æŒ‡å®šï¼Œæœƒè¦†è“‹diff_rule.jsonä¸­çš„è¨­å®š)")
    p.add_argument("--output-dir", type=Path, help="è¼¸å‡ºè³‡æ–™å¤¾ (é è¨­: data/<video_name>)ï¼›è‹¥ç‚ºè³‡æ–™å¤¾æ¨¡å¼å°‡åˆ†åˆ¥è¼¸å‡ºè‡³å„è‡ªçš„ data/<video_name>/")
    p.add_argument("--debug-pedal", action="store_true", help="å•Ÿç”¨é‡å° PEDAL å€åŸŸçš„è©³ç´°åµéŒ¯æ¨¡å¼")
    p.add_argument("--interactive", action="store_true", help="åœ¨åµéŒ¯æ¨¡å¼ä¸‹å•Ÿç”¨äº’å‹•å¼æš«åœ (éœ€æ­é… --debug-pedal)")
    p.add_argument("--force", action="store_true", help="å¼·åˆ¶é‡æ–°åˆ†æï¼Œå¿½ç•¥å·²å­˜åœ¨çš„ stage_analysis.json")
    p.add_argument("--use-stream", action="store_true", help="å¼·åˆ¶ä½¿ç”¨ä¸²æµè®€å–æ¨¡å¼ (ä¸ä¾è³´ disk cache)")
    return p.parse_args()


def main() -> None:
    args = parse_args()
    target = args.video

    if target.is_dir():
        video_files = sorted(target.glob("*.mp4"))
        if not video_files:
            print(f"âš ï¸  è³‡æ–™å¤¾ä¸­æœªæ‰¾åˆ° mp4 æª”æ¡ˆ: {target}")
            return
        print(f"ğŸ” åœ¨è³‡æ–™å¤¾ä¸­æ‰¾åˆ° {len(video_files)} æ”¯å½±ç‰‡ï¼Œé–‹å§‹é€ä¸€åˆ†æ...")
        for idx, vf in enumerate(video_files, start=1):
            print(f"\n[{idx}/{len(video_files)}] åˆ†æå½±ç‰‡: {vf.name}")
            # è¨ˆç®—é æœŸè¼¸å‡ºè·¯å¾‘ï¼Œè‹¥å­˜åœ¨ä¸”æœªæŒ‡å®š --force å‰‡è·³é
            expected_out_dir = args.output_dir if args.output_dir else resolve_video_analysis_dir(vf)
            expected_out_path = expected_out_dir / "stage_analysis.json"
            if expected_out_path.exists() and not args.force:
                print(f"â­ï¸  åµæ¸¬åˆ°å·²å­˜åœ¨: {expected_out_path}ï¼Œä½¿ç”¨ --force å¯å¼·åˆ¶é‡è·‘ï¼Œå·²è·³éã€‚")
                continue

            analyse_video(
                vf,
                roi_config_path=args.roi_config,
                cache_dir=args.cache_dir,
                rmse_threshold=args.threshold,
                output_dir=args.output_dir,  # ç›®éŒ„æ¨¡å¼ä¹Ÿå°Šé‡å‚³å…¥çš„ output_dir
                args=args,
            )
        print("\nâœ…  æ‰€æœ‰å½±ç‰‡åˆ†æå®Œæˆ")
        return

    if str(target).lower().endswith(".mp4"):
        # è¨ˆç®—é æœŸè¼¸å‡ºè·¯å¾‘ï¼Œè‹¥å­˜åœ¨ä¸”æœªæŒ‡å®š --force å‰‡æç¤ºä¸¦è·³é
        expected_out_dir = args.output_dir if args.output_dir else resolve_video_analysis_dir(target)
        expected_out_path = expected_out_dir / "stage_analysis.json"
        if expected_out_path.exists() and not args.force:
            print(f"â­ï¸  åµæ¸¬åˆ°å·²å­˜åœ¨: {expected_out_path}ï¼Œä½¿ç”¨ --force å¯å¼·åˆ¶é‡è·‘ï¼Œå·²è·³éã€‚")
            return

        analyse_video(
            target,
            roi_config_path=args.roi_config,
            cache_dir=args.cache_dir,
            rmse_threshold=args.threshold,
            output_dir=args.output_dir,
            args=args,
        )
    else:
        print(f"âŒ  è«‹æŒ‡å®š mp4 æª”æ¡ˆæˆ–åŒ…å« mp4 çš„è³‡æ–™å¤¾: {target}")


if __name__ == "__main__":
    main()
