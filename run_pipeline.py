import argparse
from pathlib import Path
import time
import cv2
import json
import traceback
from typing import List, Tuple, Any, Dict, Optional

# å¼•å…¥å·¥å…·
from utils.pipeline_utils import AsyncImageSaver
from utils.get_configs import (
    load_roi_config,
    load_stage_config,
    load_roi_header_config,
    load_ocr_char_sets_config,
    load_pattern_name_mapping,
    update_video_machine_mapping,
)
from utils.cv_processing import binarize

# å¼•å…¥å„éšæ®µæ¨¡çµ„
from extract_frame_cache import video_frame_generator
from stage_pattern_analysis import StageAnalyzer, build_segments
from auto_detect_machine_type import MachineDetector
from surgery_analysis_process import OCRProcessor
from tqdm import tqdm
import numpy as np


def _initialize_ocr_processor(
    video_name: str,
    roi_config_path: Path,
    stage_activation_dict: Dict,
    char_sets_dict: Dict,
    diff_threshold: float = 0.01
)  -> Tuple[OCRProcessor, Dict[str, Any]]:
    """
    åˆå§‹åŒ– OCR Processor
    å›å‚³: (ocr_processor, roi_dict)
    """
    # 1. è¼‰å…¥ Config
    roi_dict = load_roi_config(roi_config_path, video_name=video_name)
    
    try:
        roi_header_dict = load_roi_header_config(roi_config_path, video_name=video_name)
    except Exception:
        roi_header_dict = {}

    # 2. åˆå§‹åŒ– Processor
    ocr_processor = OCRProcessor(
        stage_activation_dict,
        roi_header_dict,
        char_sets_dict,
        diff_threshold=diff_threshold
    )
    return ocr_processor, roi_dict

def _flush_buffer(
    ocr_processor: OCRProcessor,
    roi_dict: Dict[str, Tuple[int, int, int, int]],
    frame_buffer: List[Tuple[int, np.ndarray, Dict]],
    async_saver: AsyncImageSaver,
    analysis_dir: Path,
    mode: str,
    force: bool
) -> None:
    """
    å›æº¯è™•ç† Buffer ä¸­çš„å¹€ã€‚
    """
    for buf_idx, buf_encoded_img, buf_stage in frame_buffer:
        # è§£ç¢¼ JPEG
        buf_frame = cv2.imdecode(buf_encoded_img, cv2.IMREAD_COLOR)
        if buf_frame is None: continue
        
        # åŸ·è¡Œ OCR
        ocr_processor.process_frame(buf_frame, buf_idx, roi_dict, buf_stage)
        
        # éåŒæ­¥å­˜ ROI å°åœ– 
        if mode == "detail":
            _save_roi_images(async_saver, buf_frame, roi_dict, buf_idx, analysis_dir, force)
    print("â© å›æº¯å®Œæˆï¼Œé€²å…¥å³æ™‚æ¨¡å¼")
    return 

def run_pipeline(video_path: Path, base_output_dir: Path, mode: str = "detail", force: bool = False):
    """
    å–®æ¬¡è®€å– (Single-Pass) åˆ†æç®¡ç·š
    """
    video_name = video_path.stem
    
    # ... (çœç•¥éƒ¨åˆ†è·¯å¾‘è¨­å®šä»£ç¢¼) ...
    if base_output_dir.name == video_name:
        analysis_dir = base_output_dir
    else:
        analysis_dir = base_output_dir / video_name
        
    analysis_dir.mkdir(parents=True, exist_ok=True)

    # RAM mode ä¸éœ€è¦ frame_cache ç›®éŒ„
    frame_cache_dir = None
    if mode in ["detail", "frame"]:
        frame_cache_dir = analysis_dir / "frame_cache"
        frame_cache_dir.mkdir(parents=True, exist_ok=True)

    print(f"ğŸš€ é–‹å§‹ä¸²æµåˆ†æ: {video_name} (Mode: {mode})")
    print(f"ğŸ“‚ è¼¸å‡ºç›®éŒ„: {analysis_dir}")

    # --- 1. åˆå§‹åŒ–å„å€‹çµ„ä»¶ ---
    # RAM mode ä¸éœ€è¦ AsyncImageSaver
    async_saver = AsyncImageSaver() if mode in ["detail", "frame"] else None
    
    # Configs
    stage_config_path = Path("config/surgery_stage_rois.json")
    stage_activation_path = Path("config/ocr_activation_stages.json")
    roi_config_path = Path("config/rois.json")
    char_config_path = Path("config/ocr_char_sets.json")
    cache_root = Path("data/roi_img_caches")
    
    if not stage_config_path.exists():
        print("âŒ éŒ¯èª¤: æ‰¾ä¸åˆ° config/surgery_stage_rois.json")
        return

    # Analyzers
    stage_analyzer = StageAnalyzer(stage_config_path, cache_root)
    region_matches: Dict[str, List[Tuple[int, Any, Any]]] = {
        region: [] for region in stage_analyzer.roi_dict.keys()
    }
    machine_detector = MachineDetector()
    
    # è¼‰å…¥ Configs
    stage_activation_dict = load_stage_config(stage_activation_path)
    char_sets_dict = load_ocr_char_sets_config(char_config_path)
    pattern_name_map = load_pattern_name_mapping(Path("config/pattern_name_mapping.json"))
    
    # [å„ªåŒ–] é å…ˆæª¢æŸ¥æ˜¯å¦å·²æœ‰æ©Ÿå‹è¨­å®š
    # è‹¥ rois.json ä¸­å·²æœ‰è©²å½±ç‰‡çš„ keyï¼Œè¡¨ç¤ºä¹‹å‰å·²è·‘éæˆ–å·²æ‰‹å‹•è¨­å®šï¼Œç›´æ¥ä½¿ç”¨è©²è¨­å®š
    pre_roi_dict = load_roi_config(roi_config_path)
    # load_roi_config æœƒå›å‚³æ•´å€‹ dict æˆ–ç‰¹å®š video çš„è¨­å®šï¼Œæˆ‘å€‘é€™è£¡ç›´æ¥è®€ raw json æ¯”è¼ƒæº–ç¢º
    # ä½†ç‚ºäº†æ–¹ä¾¿ï¼Œæˆ‘å€‘ç”¨ä¸€å€‹ç°¡å–®é‚è¼¯ï¼šå˜—è©¦ load_roi_config(..., video_name=video_name)
    # è§€å¯Ÿå…¶å›å‚³æ˜¯å¦ç‚º default fallbackã€‚ä½†å› ç‚º fallback é‚è¼¯åœ¨ load_roi_config å…§éƒ¨ï¼Œ
    # æœ€ç©©å¦¥çš„æ–¹å¼æ˜¯ç›´æ¥æª¢æŸ¥ video_name æ˜¯å¦åœ¨ rois.json çš„ keys ä¸­
    
    # æ©Ÿå‹åµæ¸¬ç›¸é—œ
    machine_detected = False
    machine_id = None
    ocr_processor: Optional[OCRProcessor] = None 
    roi_dict: Optional[Dict[str, Tuple[int, int, int, int]]] = None
    
    try:
        with open(roi_config_path, 'r', encoding='utf-8') as f:
            full_roi_config = json.load(f)
            if video_name in full_roi_config.get('video_machine_mapping', {}):
                # ç›´æ¥è®€å–å·²çŸ¥çš„ machine_id
                machine_id = full_roi_config['video_machine_mapping'][video_name]
                print(f"â„¹ï¸  æª¢æ¸¬åˆ°å·²çŸ¥è¨­å®š: {video_name} (Type {machine_id})ï¼Œè·³éæ©Ÿå‹åµæ¸¬ã€‚")
                machine_detected = True

                ocr_processor, roi_dict = _initialize_ocr_processor(video_name, roi_config_path, stage_activation_dict, char_sets_dict)
                
    except Exception as e:
        print(f"âš ï¸  è®€å–è¨­å®šæª”æ™‚ç™¼ç”Ÿè­¦å‘Š: {e}")
    
    # --- 2. ç‹€æ…‹è®Šæ•¸ ---
    t0 = time.time()
    processed_frames = 0
    
    # ç·©è¡å€ï¼šå„²å­˜ (frame_idx, frame_bgr, stage_result)
    # ç”¨æ–¼åœ¨æ©Ÿå‹ç¢ºèªå‰æš«å­˜ç•«é¢ï¼Œä»¥ä¾¿å›æº¯ OCR
    frame_buffer: List[Tuple[int, np.ndarray, Dict]] = []
    
    # Frame Source Setup
    cap = None
    cache_files = []
    cache_iterator = None
    total_frames = 0
    
    if mode == "read":
        if not frame_cache_dir.exists():
            print(f"âŒ [Read Mode] Cache directory not found: {frame_cache_dir}")
            return
        
        # è®€å–æ‰€æœ‰ cache æª”æ¡ˆä¸¦æŒ‰ frame index æ’åº
        # å‡è¨­æª”åæ ¼å¼ç‚º frame_{idx}.jpg
        try:
            cache_files = sorted(
                frame_cache_dir.glob("frame_*.jpg"), 
                key=lambda p: int(p.stem.split('_')[1])
            )
        except Exception as e:
             print(f"âŒ [Read Mode] Error parsing cache files: {e}")
             return

        if not cache_files:
            print(f"âŒ [Read Mode] No cached frames found in: {frame_cache_dir}")
            return
            
        total_frames = len(cache_files)
        cache_iterator = iter(cache_files)
        print(f"ğŸ“‚ [Read Mode] Found {total_frames} cached frames.")
        
    else:
        # æ”¹ç”¨ç›´æ¥æ§åˆ¶ VideoCapture ä»¥ç²å–æ™‚é–“æˆ³ä¸¦æ”¯æ´ä¸åŒæ¨¡å¼
        cap = cv2.VideoCapture(str(video_path))
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT)) if cap.isOpened() else None

    frame_timestamps: List[float] = [] # è¨˜éŒ„æ¯å¹€çš„æ™‚é–“æˆ³ (ms)
    
    try:
        # åˆå§‹åŒ– tqdm
        pbar = tqdm(total=total_frames, desc=f"Processing frames ({video_name})")
        
        frame_idx = 0
        while True:
            frame_bgr = None
            ts = 0.0
            
            if mode == "read":
                try:
                    img_path = next(cache_iterator)
                    # å¾æª”åè§£æ frame_idx
                    frame_idx = int(img_path.stem.split('_')[1])
                    
                    # [Fix] Windows ä¸‹è·¯å¾‘å«ä¸­æ–‡æ™‚ï¼Œcv2.imread æœƒå¤±æ•—ï¼Œéœ€æ”¹ç”¨ imdecode
                    # frame_bgr = cv2.imread(str(img_path))
                    img_array = np.fromfile(str(img_path), dtype=np.uint8)
                    frame_bgr = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
                    
                    if frame_bgr is None:
                        print(f"âš ï¸ [Read Mode] Failed to read image: {img_path}")
                        continue
                    # Read mode ä¸‹æ™‚é–“æˆ³æš«æ™‚è¨­ç‚º 0 æˆ–ä¾è³´å¤–éƒ¨è¨˜éŒ„ (æ­¤è™•ç°¡åŒ–)
                    ts = 0.0 
                except StopIteration:
                    break
            else:
                if not cap.isOpened():
                    break
                    
                # ç²å–ç•¶å‰æ™‚é–“æˆ³ (åœ¨ read ä¹‹å‰ç²å– POS_MSEC)
                ts = cap.get(cv2.CAP_PROP_POS_MSEC)
                
                ret, frame_bgr = cap.read()
                if not ret:
                    break
                
                if frame_bgr is None or frame_bgr.size == 0:
                    frame_idx += 1 # å³ä½¿æ˜¯å£å¹€ï¼Œç´¢å¼•ä¹Ÿè¦éå¢ï¼Œä¿æŒæ™‚é–“è»¸ä¸€è‡´
                    continue

            # è¨˜éŒ„æ™‚é–“æˆ³
            frame_timestamps.append(ts)
            
            processed_frames += 1
            pbar.update(1)
            
            # [Step A] æ ¹æ“š mode æ±ºå®šæ˜¯å¦å­˜ Frame Cache (å¤§åœ–)
            # mode='detail' or 'frame' -> å­˜å¤§åœ–
            # mode='ram' -> ä¸å­˜
            # mode='read' -> å·²ç¶“å¾ cache è®€äº†ï¼Œä¸éœ€è¦å†å­˜
            if mode in ["detail", "frame"]:
                cache_path = frame_cache_dir / f"frame_{frame_idx}.jpg"
                if force or not cache_path.exists():
                    async_saver.save(frame_bgr, cache_path, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
            
            # [Step B] éšæ®µåˆ†æ (Stage Analysis)

            # é€™æ˜¯é€šç”¨çš„ï¼Œä¸ä¾è³´æ©Ÿå‹
            stage_res = stage_analyzer.process_frame(frame_bgr, frame_idx)
            for region_name, res in stage_res.items():
                pid = None
                rmse = None
                if isinstance(res, dict):
                    pid = res.get("pattern_id")
                    rmse = res.get("rmse")
                region_matches.setdefault(region_name, []).append((frame_idx, pid, rmse))
            current_stage_pattern = stage_res.get("STAGE", {}).get("pattern_id")
            
            # [Step C] æ©Ÿå‹åµæ¸¬èˆ‡ OCR åˆ†æ”¯é‚è¼¯
            if not machine_detected:
                # 1. è¨˜æ†¶é«”å„ªåŒ–ï¼šå°‡ Frame å£“ç¸®ç‚º JPEG Bytes å­˜å…¥ Buffer
                success, encoded_img = cv2.imencode('.jpg', frame_bgr, [int(cv2.IMWRITE_JPEG_QUALITY), 85])
                if success:
                    frame_buffer.append((frame_idx, encoded_img, stage_res))
                
                # 2. é€å¹€åµæ¸¬ (Frame-by-Frame Detection)
                header_config = load_roi_header_config(video_name=None) # é è¨­æ©Ÿå‹1é…ç½®
                
                detected_id = None
                if header_config and "region1" in header_config:
                    detected_id = machine_detector.detect_from_frame(frame_bgr, header_config["region1"])
                
                # æ¢ä»¶A: æˆåŠŸåµæ¸¬åˆ°æ©Ÿå‹
                # æ¢ä»¶B: Buffer è¶…éå®‰å…¨ä¸Šé™ (ä¾‹å¦‚ 100000 å¹€)ï¼Œå¼·åˆ¶ä½¿ç”¨é è¨­æ©Ÿå‹
                force_resolve = len(frame_buffer) > 100000
                
                if detected_id is not None or force_resolve:
                    if detected_id:
                        machine_id = detected_id
                        update_video_machine_mapping(video_name, machine_id)
                        print(f"\nâœ… åµæ¸¬æ©Ÿå‹: Type {machine_id} (Frame {frame_idx})")
                    else:
                        machine_id = 1
                        print(f"\nâš ï¸ è­¦å‘Šï¼šBuffer è¶…é 100000 å¹€ä»æœªåµæ¸¬åˆ°æ©Ÿå‹ï¼Œå¼·åˆ¶ä½¿ç”¨é è¨­ Type 1")

                    if 'pbar' in locals(): pbar.clear()
                    machine_detected = True
                    
                    ocr_processor, roi_dict = _initialize_ocr_processor(video_name, roi_config_path, stage_activation_dict, char_sets_dict)
                    _flush_buffer(ocr_processor, roi_dict, frame_buffer, async_saver, analysis_dir, mode, force)
                    frame_buffer = [] # æ¸…ç©º Buffer

            else:
                # æ©Ÿå‹å·²ç¢ºèªï¼šå³æ™‚è™•ç†æ¨¡å¼
                # ç›´æ¥åŸ·è¡Œ OCR
                if ocr_processor and roi_dict:
                    ocr_processor.process_frame(frame_bgr, frame_idx, roi_dict, stage_res)
                    
                    # éåŒæ­¥å­˜ ROI å°åœ–
                    if mode == "detail":
                        _save_roi_images(async_saver, frame_bgr, roi_dict, frame_idx, analysis_dir, force)

            frame_idx += 1 # ç¢ºä¿æ¯ä¸€å¹€ç´¢å¼•éå¢

    except KeyboardInterrupt:
        print("\nâš ï¸ ä½¿ç”¨è€…ä¸­æ–·")
    except Exception as e:
        print(f"\nâŒ ç™¼ç”Ÿæœªé æœŸçš„éŒ¯èª¤: {e}")
        traceback.print_exc()
        
    # [Step D] çµæŸè™•ç†ï¼šå„²å­˜çµæœ
    if ocr_processor:
        print(f"\nğŸ’¾ å„²å­˜ OCR çµæœè‡³: {analysis_dir}")
        ocr_processor.save_results(analysis_dir)

    stage_total = total_frames if total_frames is not None else processed_frames
    _write_stage_analysis(video_name, analysis_dir, region_matches, stage_total, pattern_name_map)
        
    # ç­‰å¾… IO (åªæœ‰åœ¨æœ‰ async_saver æ™‚æ‰éœ€è¦)
    if async_saver:
        print("â³ ç­‰å¾…èƒŒæ™¯å„²å­˜å®Œæˆ...")
        async_saver.stop()
    print(f"\nâœ… åˆ†æå®Œæˆï¼Œç¸½è€—æ™‚: {time.time() - t0:.2f}s (Frames: {processed_frames})")


def _save_roi_images(
    saver: AsyncImageSaver,
    frame: np.ndarray,
    roi_config: Dict[str, Tuple[int, int, int, int]],
    frame_idx: int,
    base_dir: Path,
    force: bool,
) -> None:
    """å„²å­˜ ROI åŸåœ–èˆ‡äºŒå€¼åœ–ï¼Œèˆ‡èˆŠæµç¨‹ä¸€è‡´ã€‚"""
    for region_name, (x1, y1, x2, y2) in roi_config.items():
        region_dir = base_dir / region_name
        region_dir.mkdir(parents=True, exist_ok=True)

        try:
            roi_bgr = frame[y1:y2, x1:x2]
            if roi_bgr.size == 0:
                continue
        except Exception:
            continue

        orig_path = region_dir / f"frame_{frame_idx}.png"
        bin_path = region_dir / f"frame_{frame_idx}_binary.png"

        if force or not orig_path.exists():
            saver.save(roi_bgr, orig_path)

        if force or not bin_path.exists():
            try:
                roi_binary = binarize(roi_bgr, method="rule")
                saver.save(roi_binary, bin_path)
            except Exception:
                continue


def _write_stage_analysis(
    video_name: str,
    analysis_dir: Path,
    region_matches: Dict[str, List[Tuple[int, Optional[int], Optional[float]]]],
    total_frames: int,
    pattern_name_map: Dict[str, Dict[str, str]],
) -> None:
    regions_output: Dict[str, List[Dict[str, Any]]] = {}
    for region_name, matches in region_matches.items():
        if not matches:
            regions_output[region_name] = []
            continue
        matches.sort(key=lambda t: t[0])
        region_map = pattern_name_map.get(region_name, {})
        segments = build_segments(matches, region_map)
        cleaned_segments: List[Dict[str, Any]] = []
        for seg in segments:
            start = int(seg.get("start_frame", 0))
            end = int(seg.get("end_frame", start))
            if end < start:
                end = start
            seg["start_frame"] = start
            seg["end_frame"] = end
            seg["frame_count"] = max(0, end - start + 1)
            cleaned_segments.append(seg)
        regions_output[region_name] = cleaned_segments

    payload = {
        "video": video_name,
        "total_frames": total_frames,
        "regions": regions_output,
    }

    out_path = analysis_dir / "stage_analysis.json"
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)


def main() -> None:
    parser = argparse.ArgumentParser(description="Single-pass surgery pipeline")
    parser.add_argument("--video", type=Path, required=True, help="å½±ç‰‡æª”æˆ–åŒ…å«å½±ç‰‡çš„è³‡æ–™å¤¾")
    parser.add_argument("--output-dir", type=Path, default=Path("data"), help="è¼¸å‡ºæ ¹ç›®éŒ„")
    parser.add_argument("--force", action="store_true", help="è¦†è“‹æ—¢æœ‰ frame cache èˆ‡ ROI åœ–ç‰‡")
    parser.add_argument("--mode", type=str, default="ram", choices=["detail", "frame", "ram", "read"],
                       help="å­˜æª”æ¨¡å¼: detail (å­˜å¤§åœ–+ROI), frame (åªå­˜å¤§åœ–), ram (ä¸å­˜åœ–, æœ€å¿«), read (è®€å–å¿«å–)")
    args = parser.parse_args()

    target_path = args.video
    if not target_path.exists():
        print(f"âŒ è·¯å¾‘ä¸å­˜åœ¨: {target_path}")
        return

    if target_path.is_file():
        video_files = [target_path]
    else:
        video_files = sorted({*target_path.glob("*.mp4"), *target_path.glob("*.MP4")})
        if not video_files:
            print(f"âš ï¸ åœ¨ç›®éŒ„ {target_path} ä¸­æœªæ‰¾åˆ° .mp4 æª”æ¡ˆ")
            return
        print(f"ğŸ“‚ æ‰¾åˆ° {len(video_files)} å€‹å½±ç‰‡æª”æ¡ˆï¼Œæº–å‚™é–‹å§‹æ‰¹æ¬¡åˆ†æ...")

    for idx, vf in enumerate(video_files, start=1):
        print(f"\n{'=' * 60}")
        print(f"[{idx}/{len(video_files)}] ğŸ¬ è™•ç†å½±ç‰‡: {vf.name} (Mode: {args.mode})")
        print(f"{'=' * 60}")
        try:
            run_pipeline(vf, args.output_dir, args.mode, args.force)
        except Exception as e:
            print(f"âŒ è™•ç† {vf.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            traceback.print_exc()

    print("\nâœ… æ‰€æœ‰ä»»å‹™å®Œæˆ")


if __name__ == "__main__":
    main()
